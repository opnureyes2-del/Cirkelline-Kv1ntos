# CIRKELLINE LOGSTASH PIPELINE
# ============================
# Processes logs from Cirkelline backend and related services
#
# Version: v1.3.5
# Date: 2025-12-17

input {
  # TCP input for direct log shipping
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp", "cirkelline"]
  }

  # Beats input (from Filebeat)
  beats {
    port => 5044
    tags => ["beats"]
  }

  # File input for local logs
  file {
    path => "/var/log/host/ckc/*.log"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_ckc"
    tags => ["file", "ckc"]
    codec => plain {
      charset => "UTF-8"
    }
  }
}

filter {
  # Parse JSON logs from Cirkelline backend
  if "cirkelline" in [tags] or "beats" in [tags] {
    json {
      source => "message"
      target => "parsed"
      skip_on_invalid_json => true
    }

    # Extract common fields
    if [parsed] {
      mutate {
        add_field => {
          "log_level" => "%{[parsed][level]}"
          "logger" => "%{[parsed][name]}"
          "log_message" => "%{[parsed][message]}"
        }
      }
    }
  }

  # Parse CKC routine logs
  if "ckc" in [tags] {
    grok {
      match => {
        "message" => [
          "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{WORD:level}\] %{GREEDYDATA:log_message}",
          "%{TIMESTAMP_ISO8601:timestamp} - %{WORD:routine} - %{WORD:level} - %{GREEDYDATA:log_message}"
        ]
      }
      tag_on_failure => ["_grokparsefailure_ckc"]
    }

    # Identify routine type
    if [source] =~ /sorting_0333/ {
      mutate { add_field => { "routine_type" => "sorting_0333" } }
    } else if [source] =~ /morning_sync/ {
      mutate { add_field => { "routine_type" => "morning_sync_0900" } }
    } else if [source] =~ /evening_opt/ {
      mutate { add_field => { "routine_type" => "evening_opt_2121" } }
    }
  }

  # Parse FastAPI access logs
  if [source] =~ /uvicorn/ or [message] =~ /INFO.*"(GET|POST|PUT|DELETE)/ {
    grok {
      match => {
        "message" => '%{IP:client_ip} - - \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:http_version}" %{NUMBER:status_code} %{NUMBER:response_size}'
      }
      tag_on_failure => ["_grokparsefailure_access"]
    }

    if [status_code] {
      mutate {
        convert => { "status_code" => "integer" }
        convert => { "response_size" => "integer" }
      }
    }
  }

  # Add metadata
  mutate {
    add_field => {
      "environment" => "development"
      "application" => "cirkelline"
      "version" => "v1.3.5"
    }
  }

  # Parse timestamp if present
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "dd/MMM/yyyy:HH:mm:ss Z"]
      target => "@timestamp"
    }
  }

  # Classify log level
  if [level] or [log_level] {
    mutate {
      uppercase => ["level", "log_level"]
    }

    if [level] in ["ERROR", "CRITICAL", "FATAL"] or [log_level] in ["ERROR", "CRITICAL", "FATAL"] {
      mutate { add_tag => ["error"] }
    } else if [level] == "WARNING" or [log_level] == "WARNING" {
      mutate { add_tag => ["warning"] }
    }
  }

  # Remove temporary fields
  mutate {
    remove_field => ["parsed", "host", "agent"]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "cirkelline-logs-%{+YYYY.MM.dd}"
    template_name => "cirkelline-logs"
    template_overwrite => true
  }

  # Debug output (comment out in production)
  # stdout {
  #   codec => rubydebug
  # }
}
